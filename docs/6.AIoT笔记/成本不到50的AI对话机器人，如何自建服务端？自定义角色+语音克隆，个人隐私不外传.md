年前看到一款**开源项目** - 小智AI对话机器人：

![](https://i-blog.csdnimg.cn/img_convert/ba77ebc41d5e0bf59fb1d32c6338ad77.jpeg)

基于 ESP-32 核心板开发，实时语音对话，可玩性太高了。

而下面这张图，就基本包含了 AI 语音玩具需要的所有东西，**成本不到50元**，忍不住我也入手了一个！

![](https://i-blog.csdnimg.cn/img_convert/861ccf6d205717c89dd32eada43d1fa5.jpeg)

先看最终效果：


[video(video-iDD2IdX5-1740623650445)(type-csdn)(url-https://live.csdn.net/v/embed/463876)(image-https://i-blog.csdnimg.cn/direct/91aaa96cebdb44689f1b320f220ef1cf.png)(title-)]


不过，因为 ESP-32 核心板的计算能力有限，所有对话数据，**都得发往公网服务器处理**。

对在意个人隐私的用户而言，搭建本地服务，就在所难免。

于是动手折腾了一番，今天把`搭建本地服务端`的过程分享给大家，希望给有类似需求的朋友一点参考和帮助。

## 1. 项目简介
> 项目地址：[https://github.com/78/xiaozhi-esp32](https://github.com/78/xiaozhi-esp32)
>
> 项目文档：[https://ccnphfhqs21z.feishu.cn/wiki/F5krwD16viZoF0kKkvDcrZNYnhb](https://ccnphfhqs21z.feishu.cn/wiki/F5krwD16viZoF0kKkvDcrZNYnhb)

作者提到，开源这个项目，是为了更多人入门 AI 硬件开发。

的确，当下 AI 大模型的发展速度可谓日新月异。一旦落地到生活日常，可玩的东西就太多了。。。

目前这个板子已经实现：

- **离线语音唤醒**：通过 `ESP-SR` 实现。

- **流式语音对话**：支持 `WebSocket` 和 `UDP` 协议。

- **声纹识别**：识别说话者身份。

- **短期记忆**：对每轮对话进行总结。

- **自定义角色**：支持提示词和音色设置。

- **联网能力**：支持 Wi-Fi 和 4G 接入。


作者把硬件端的代码开源了，为此，想要玩玩的朋友**只需两步**：
- 购买所需硬件，回来接好线；
- 刷入最新的固件。

接线可参考：[https://ccnphfhqs21z.feishu.cn/wiki/EH6wwrgvNiU7aykr7HgclP09nCh](https://ccnphfhqs21z.feishu.cn/wiki/EH6wwrgvNiU7aykr7HgclP09nCh)

这里也贴下我当初的接线图，供参考：

![](https://i-blog.csdnimg.cn/img_convert/8ea1fb473be599934e05e8e082d272b2.png)

完成上述两步，接入作者的官方服务器，AI 会话，即刻启程！

---

本篇主要想和大家聊聊**服务端如何搭建**：
- 一是：所有**隐私/敏感数据**掌握在自己手里；
- 二是：实现**更多个性化、定制化功能**，比如角色自定义、音色克隆、接入知识库，甚至接入产品数据-打造智能客服。

要实现上述对话逻辑，笔者梳理了下大致流程：

![](https://i-blog.csdnimg.cn/img_convert/25d7690fa702d819bc084fc9eb0ee8ae.png)

## 2. 自建服务端
> 因为语音识别、语音克隆等模型推理需要显卡，确保一张 8G+ 显存的显卡即可。
>
> 服务端代码参考：[https://github.com/78/xiaozhi](https://github.com/78/xiaozhi)

服务端代码目录结构如下：

```
.
├── asr-server
├── asr-worker
├── main-server
└── tts-server
```
**模块化设计**：每个功能模块采用独立的目录，便于开发和维护，提高系统的可扩展性和可维护性。

**职责分离**：
- `asr-server`+`asr-worker`：提供语音活动监测、语音转文本、说话人识别等服务；
- `tts-server`：提供音色管理、音色克隆、语音合成等服务，对接本地部署的语音模型；
- `main-server`：主服务，负责协调语音识别、大模型、语音合成等各种服务，并对接后端数据库。

**大致实现逻辑如下**：

![](https://i-blog.csdnimg.cn/img_convert/9f3cf009aaba6c212e8f824a2864bf26.png)


## 3. 前端控制台

尽管前端界面并不需要多复杂，但为了方便后续迭代，最终还是决定采用前后端分离进行开发，技术选型如下：

- 前端：vue3；
- 后端：fastapi + sqlalchemy。

其中前端主要用到的工具有：
- `Vite`：实现项目打包管理
- `Vue-Router`：实现单页面应用（SPA）的路由控制
- `Pinia`：Vue 3 推荐的状态管理库
- `Element-Plus`：基于 Vue 3 的 UI 组件库，实现界面布局

前端开发不复杂，最关键的是数据库表的设计。一旦这里的逻辑理清，后面就相对顺畅了。


### 3.1 注册登录

![](https://i-blog.csdnimg.cn/img_convert/2b644fff63d50c43f689dfd0477de48d.png)

### 3.2 设备管理

![](https://i-blog.csdnimg.cn/img_convert/19eb64857ab6f3316262eb3010309218.png)

#### 3.2.1 配置角色

每一个设备，对应一个角色。`配置角色`包括两部分：
- **角色的人设**，包括系统默认的角色模板，和用户自定义的模板
- **角色的大脑**：也即角色大模型；
- **角色的音色**：支持用户上传的克隆音色。

![](https://i-blog.csdnimg.cn/img_convert/22a3e18d49e83e4f8f83cb237ccf3e6e.png)

#### 3.2.2 说话人识别
`角色定义`是让`AI成为谁`，而`说话人识别`则是`让 AI 知道你是谁`，这里是*通过判断不同人的音色*来实现。

当点击`添加说话人`时，系统会从后端拉取所有会话的语音向量，可以从中选择一条最清晰的，作为当前`说话人`的判断依据。

![](https://i-blog.csdnimg.cn/img_convert/e5ddcf71add3e13ad479551e43faa23e.png)

`说话人`管理界面，则用于配置不同`说话人`的角色设定：

![](https://i-blog.csdnimg.cn/img_convert/6cbadff071c192bd14e3fc9bda3af23c.png)

#### 3.2.3 对话记忆

每轮对话结束后，AI 会进行提炼总结，作为`记忆`存入数据库。后续对话时，自动拉取`历史记忆`作为上下文参考。

当然，也支持在页面编辑、增加记忆内容，作为 AI 总结的补充。

![](https://i-blog.csdnimg.cn/img_convert/a44431f1685f6ccaa7b45fecdb180758.png)

### 3.3 角色管理

![](https://i-blog.csdnimg.cn/img_convert/de7f8d6b6db521b77e7e2a04bda32aa1.png)

### 3.4 大模型管理

![](https://i-blog.csdnimg.cn/img_convert/7c4521ed396946ef05632e38a43ed6c1.png)

### 3.5 音色管理

![](https://i-blog.csdnimg.cn/img_convert/cfea3c4bdfa55f60910e26740ce2f864.png)

支持用户上传自己的语音片段，实现**音色克隆**。

点击**音色克隆**，上传音频文件后，后端自动触发语音识别，点击`保存`后，你的音色就会保存在后端。在`自定义角色`时，可根据这里的`音色ID`和`音色名称`进行选择。

![](https://i-blog.csdnimg.cn/img_convert/58ad18d53aeab0ad111adf7e33944935.png)


## 写在最后

本文和大家梳理了`小智 AI 对话机器人`-`自建服务端`的实现过程。

如果对你有帮助，欢迎**点赞收藏**备用。

欢迎感兴趣的朋友一起玩，代码等有空完善后开源出来。

--- 

为方便大家交流，新建了一个 `AI 交流群`，公众号后台「联系我」，拉你进群。
